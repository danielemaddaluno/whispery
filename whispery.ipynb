{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Whispery: a tool to easily convert an audio/video file to text using **whisper** by *OpenAI*."
      ],
      "metadata": {
        "id": "LcGcc5RG3Ft4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jc0sRikfkSz_"
      },
      "outputs": [],
      "source": [
        "# @title 1. **GPU Checker** { vertical-output: true, display-mode: \"form\" }\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU is available üëç, you can skip to the step 2. ü¶Ñ\")\n",
        "else:\n",
        "    print(\"GPU is NOT available üëé, follow the instructions written below. üìö\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "If GPU is still not available, you can try changing the runtime following these steps:\n",
        "\n",
        "1. Click on <ins>Runtime</ins> in the top menu.\n",
        "2. Choose <ins>Change runtime type</ins> from the dropdown menu.\n",
        "3. In the <ins>Hardware accelerator</ins> section, select <ins>**T4 GPU**</ins>.\n",
        "5. Click on <ins>Save</ins> to apply the changes.\n",
        "\n",
        "After changing the runtime, you can run again the code snippet above to check if the GPU is available.\n",
        "\n",
        "If you have exhausted your free GPU quota, you can run it without using the GPU; it will simply take longer to execute, and there is no guarantee it will finish."
      ],
      "metadata": {
        "id": "zVdvRCyRrzI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 2. Install **whisper** and **ffmpeg** { display-mode: \"form\" }\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!sudo apt update && sudo apt install ffmpeg"
      ],
      "metadata": {
        "id": "A2FnQsexqsMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3. **Run whisper with an audio/video file** { display-mode: \"form\" }\n",
        "from google.colab import files\n",
        "\n",
        "# @markdown Select these options, then **run** to proceed with the <ins>**upload**</ins>.\n",
        "\n",
        "# Language selection dropdown with search\n",
        "Language = \"Autodetect\" # @param ['Autodetect','Afrikaans', 'Albanian', 'Amharic', 'Arabic', 'Armenian', 'Assamese', 'Azerbaijani', 'Bashkir', 'Basque', 'Belarusian', 'Bengali', 'Bosnian', 'Breton', 'Bulgarian', 'Burmese', 'Cantonese', 'Castilian', 'Catalan', 'Chinese', 'Croatian', 'Czech', 'Danish', 'Dutch', 'English', 'Estonian', 'Faroese', 'Finnish', 'Flemish', 'French', 'Galician', 'Georgian', 'German', 'Greek', 'Gujarati', 'Haitian', 'Haitian Creole', 'Hausa', 'Hawaiian', 'Hebrew', 'Hindi', 'Hungarian', 'Icelandic', 'Indonesian', 'Italian', 'Japanese', 'Javanese', 'Kannada', 'Kazakh', 'Khmer', 'Korean', 'Lao', 'Latin', 'Latvian', 'Letzeburgesch', 'Lingala', 'Lithuanian', 'Luxembourgish', 'Macedonian', 'Malagasy', 'Malay', 'Malayalam', 'Maltese', 'Mandarin', 'Maori', 'Marathi', 'Moldavian', 'Moldovan', 'Mongolian', 'Myanmar', 'Nepali', 'Norwegian', 'Nynorsk', 'Occitan', 'Panjabi', 'Pashto', 'Persian', 'Polish', 'Portuguese', 'Punjabi', 'Pushto', 'Romanian', 'Russian', 'Sanskrit', 'Serbian', 'Shona', 'Sindhi', 'Sinhala', 'Sinhalese', 'Slovak', 'Slovenian', 'Somali', 'Spanish', 'Sundanese', 'Swahili', 'Swedish', 'Tagalog', 'Tajik', 'Tamil', 'Tatar', 'Telugu', 'Thai', 'Tibetan', 'Turkish', 'Turkmen', 'Ukrainian', 'Urdu', 'Uzbek', 'Valencian', 'Vietnamese', 'Welsh', 'Yiddish', 'Yoruba' ]\n",
        "\n",
        "# Model selection dropdown\n",
        "Model = \"medium\" # @param ['tiny', 'base', 'small', 'medium', 'large']\n",
        "\n",
        "# Task selection\n",
        "Translate = False  # @param {'type': 'boolean'}\n",
        "\n",
        "# File uploader\n",
        "uploads = files.upload()\n",
        "\n",
        "\n",
        "if uploads:\n",
        "  for name, contents in uploads.items():\n",
        "    wlanguage = '' if Language == 'Autodetect' else '--language ' + Language\n",
        "    wmodel = '--model ' + Model\n",
        "    wtask = '--task translate' if Translate else ''\n",
        "    !echo whisper \"$name\" \"$wmodel\" \"$wlanguage\" \"$wtask\" --output_dir outputs\n",
        "    !whisper \"$name\" \"$wmodel\" \"$wlanguage\" \"$wtask\" --output_dir outputs\n",
        "else:\n",
        "    print(\"No file uploaded. Run again.\")"
      ],
      "metadata": {
        "id": "50iSPV6Zknn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 4. **Outputs download** { display-mode: \"form\" }\n",
        "import shutil\n",
        "\n",
        "# Replace '/content/folder_to_download' with the path to the folder you want to download\n",
        "folder_to_download = '/content/outputs'\n",
        "\n",
        "# Replace 'folder_to_download.zip' with the desired name for the zip file\n",
        "zip_file_name = 'outputs.zip'\n",
        "\n",
        "# Create a zip file of the folder\n",
        "shutil.make_archive(zip_file_name.replace('.zip', ''), 'zip', folder_to_download)\n",
        "\n",
        "# Download the zip file\n",
        "from google.colab import files\n",
        "files.download(zip_file_name)"
      ],
      "metadata": {
        "id": "wAInwi4sv-qe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 5. **Remove all files** { display-mode: \"form\" }\n",
        "!rm -r *"
      ],
      "metadata": {
        "id": "yznL9J4a3xAY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}